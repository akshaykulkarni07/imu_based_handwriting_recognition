{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from torch.autograd import Variable\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52500, 10)\n",
      "(6600, 10)\n",
      "(6600, 10)\n"
     ]
    }
   ],
   "source": [
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('final_data/train.csv', header = None)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('final_data/test.csv', header = None)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('final_data/val.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df.iloc[idx : idx + 300, 6 : ].values\n",
    "        ind = np.argmax(np.sum(y, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 6 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + 300, : 6].values\n",
    "        x = x.astype('float')\n",
    "        assert(x.shape == (300, 6))\n",
    "        assert(label.shape == (4, ))\n",
    "        return x, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 300, 6])\n",
      "torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 300\n",
    "train_batch_size = 8\n",
    "batch_size = 2\n",
    "train_indices = [(i * reqd_len) for i in range(len(trainset) // reqd_len)]\n",
    "val_indices = [(i * reqd_len) for i in range(len(valset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(testset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)\n",
    "\n",
    "signal, label = next(iter(trainloader))\n",
    "print(signal.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298.0\n",
      "296.0\n",
      "294.0\n"
     ]
    }
   ],
   "source": [
    "# print(len(trainloader))\n",
    "# print(len(testloader))\n",
    "# print(len(valloader))\n",
    "def output_size(n, f, p = 0, s = 1):\n",
    "    return (((n + 2 * p - f) / s) + 1)\n",
    "print(output_size(300, 3))\n",
    "print(output_size(298, 3))\n",
    "print(output_size(296, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(6, 10, 3)\n",
    "        self.conv2 = nn.Conv1d(10, 15, 3)\n",
    "        self.conv3 = nn.Conv1d(15, 20, 3)\n",
    "        self.fc1 = nn.Linear(294 * 20, 512)\n",
    "        self.fc2 = nn.Linear(512, 4)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal = signal.view(-1, 6, 300)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = out.view(-1, 294 * 20)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  6562  loss =  1.3489880561828613\n",
      "epoch =  0  step =  20  of total steps  6562  loss =  1.0555881261825562\n",
      "epoch :  0  /  30  | TL :  2.14180094287509  | VL :  1.0195603370666504\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  6562  loss =  1.0251587629318237\n",
      "epoch =  1  step =  20  of total steps  6562  loss =  0.46779364347457886\n",
      "epoch :  1  /  30  | TL :  0.6004469352109092  | VL :  0.2959310710430145\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  6562  loss =  0.19593290984630585\n",
      "epoch =  2  step =  20  of total steps  6562  loss =  0.06102434918284416\n",
      "epoch :  2  /  30  | TL :  0.16898431753118834  | VL :  0.07256618142127991\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  6562  loss =  0.062477145344018936\n",
      "epoch =  3  step =  20  of total steps  6562  loss =  0.02252955175936222\n",
      "epoch :  3  /  30  | TL :  0.0806790887422505  | VL :  0.032675620168447495\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  6562  loss =  0.027937553822994232\n",
      "epoch =  4  step =  20  of total steps  6562  loss =  0.376395583152771\n",
      "epoch :  4  /  30  | TL :  0.0689215310184019  | VL :  0.0185655876994133\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  6562  loss =  0.025575457140803337\n",
      "epoch =  5  step =  20  of total steps  6562  loss =  0.010384554043412209\n",
      "epoch :  5  /  30  | TL :  0.0525841565713996  | VL :  0.046088699251413345\n",
      "epoch =  6  step =  0  of total steps  6562  loss =  0.030232446268200874\n",
      "epoch =  6  step =  20  of total steps  6562  loss =  0.05691888928413391\n",
      "epoch :  6  /  30  | TL :  0.053093803425629936  | VL :  0.05668995529413223\n",
      "epoch =  7  step =  0  of total steps  6562  loss =  0.027539534494280815\n",
      "epoch =  7  step =  20  of total steps  6562  loss =  0.006056744139641523\n",
      "epoch :  7  /  30  | TL :  0.06144374963783082  | VL :  0.027535105124115944\n",
      "epoch =  8  step =  0  of total steps  6562  loss =  0.005244274158030748\n",
      "epoch =  8  step =  20  of total steps  6562  loss =  0.009082633070647717\n",
      "epoch :  8  /  30  | TL :  0.008798115543045458  | VL :  0.00253780628554523\n",
      "saving model\n",
      "epoch =  9  step =  0  of total steps  6562  loss =  0.0036027319729328156\n",
      "epoch =  9  step =  20  of total steps  6562  loss =  0.004898081999272108\n",
      "epoch :  9  /  30  | TL :  0.008553427286512618  | VL :  0.013071751222014427\n",
      "epoch =  10  step =  0  of total steps  6562  loss =  0.00436435779556632\n",
      "epoch =  10  step =  20  of total steps  6562  loss =  0.12011168897151947\n",
      "epoch :  10  /  30  | TL :  0.014058972259850375  | VL :  0.0017621456645429134\n",
      "saving model\n",
      "epoch =  11  step =  0  of total steps  6562  loss =  0.0009169431286863983\n",
      "epoch =  11  step =  20  of total steps  6562  loss =  0.0019750730134546757\n",
      "epoch :  11  /  30  | TL :  0.009717388832498165  | VL :  0.001641261507757008\n",
      "saving model\n",
      "epoch =  12  step =  0  of total steps  6562  loss =  0.01613951474428177\n",
      "epoch =  12  step =  20  of total steps  6562  loss =  0.0012153646675869823\n",
      "epoch :  12  /  30  | TL :  0.006454760837923026  | VL :  0.0013575019547715783\n",
      "saving model\n",
      "epoch =  13  step =  0  of total steps  6562  loss =  0.001853463938459754\n",
      "epoch =  13  step =  20  of total steps  6562  loss =  0.00044758786680176854\n",
      "epoch :  13  /  30  | TL :  0.003596913002963577  | VL :  0.0037718566600233316\n",
      "epoch =  14  step =  0  of total steps  6562  loss =  0.002520430600270629\n",
      "epoch =  14  step =  20  of total steps  6562  loss =  0.0035868429113179445\n",
      "epoch :  14  /  30  | TL :  0.002302235027032328  | VL :  0.0011723096249625087\n",
      "saving model\n",
      "epoch =  15  step =  0  of total steps  6562  loss =  0.003163744229823351\n",
      "epoch =  15  step =  20  of total steps  6562  loss =  0.001324494369328022\n",
      "epoch :  15  /  30  | TL :  0.0014798721184931872  | VL :  0.0011769236298277974\n",
      "epoch =  16  step =  0  of total steps  6562  loss =  0.007058275863528252\n",
      "epoch =  16  step =  20  of total steps  6562  loss =  0.0014058833476155996\n",
      "epoch :  16  /  30  | TL :  0.0014654389385777037  | VL :  0.0013885749503970146\n",
      "epoch =  17  step =  0  of total steps  6562  loss =  0.000726377300452441\n",
      "epoch =  17  step =  20  of total steps  6562  loss =  0.00033961550798267126\n",
      "epoch :  17  /  30  | TL :  0.0011512118501178477  | VL :  0.0008283869829028845\n",
      "saving model\n",
      "epoch =  18  step =  0  of total steps  6562  loss =  0.0017438149079680443\n",
      "epoch =  18  step =  20  of total steps  6562  loss =  0.003653548890724778\n",
      "epoch :  18  /  30  | TL :  0.0010482346780398594  | VL :  0.0009496280690655112\n",
      "epoch =  19  step =  0  of total steps  6562  loss =  0.0013516609324142337\n",
      "epoch =  19  step =  20  of total steps  6562  loss =  0.000891893170773983\n",
      "epoch :  19  /  30  | TL :  0.0009782039085707982  | VL :  0.0009099505259655416\n",
      "epoch =  20  step =  0  of total steps  6562  loss =  0.0016846308717504144\n",
      "epoch =  20  step =  20  of total steps  6562  loss =  0.0002679038152564317\n",
      "epoch :  20  /  30  | TL :  0.0009716659399037738  | VL :  0.0008341631037183106\n",
      "epoch =  21  step =  0  of total steps  6562  loss =  0.000503977236803621\n",
      "epoch =  21  step =  20  of total steps  6562  loss =  0.0006483839242719114\n",
      "epoch :  21  /  30  | TL :  0.0008621364367649047  | VL :  0.0007277848781086504\n",
      "saving model\n",
      "epoch =  22  step =  0  of total steps  6562  loss =  0.00047058850759640336\n",
      "epoch =  22  step =  20  of total steps  6562  loss =  0.0003378220135346055\n",
      "epoch :  22  /  30  | TL :  0.000783028977041665  | VL :  0.0006669550784863532\n",
      "saving model\n",
      "epoch =  23  step =  0  of total steps  6562  loss =  0.0005401264643296599\n",
      "epoch =  23  step =  20  of total steps  6562  loss =  0.0005255425348877907\n",
      "epoch :  23  /  30  | TL :  0.0006120126698598531  | VL :  0.0008964926237240434\n",
      "epoch =  24  step =  0  of total steps  6562  loss =  0.001050537102855742\n",
      "epoch =  24  step =  20  of total steps  6562  loss =  0.00024333357578143477\n",
      "epoch :  24  /  30  | TL :  0.0006220780591580219  | VL :  0.0006129883113317192\n",
      "saving model\n",
      "epoch =  25  step =  0  of total steps  6562  loss =  0.00014987601025495678\n",
      "epoch =  25  step =  20  of total steps  6562  loss =  0.000988083891570568\n",
      "epoch :  25  /  30  | TL :  0.0005799531077389561  | VL :  0.000627553032245487\n",
      "epoch =  26  step =  0  of total steps  6562  loss =  0.0004930873401463032\n",
      "epoch =  26  step =  20  of total steps  6562  loss =  0.00031251832842826843\n",
      "epoch :  26  /  30  | TL :  0.0004987696645132798  | VL :  0.0005323425284586847\n",
      "saving model\n",
      "epoch =  27  step =  0  of total steps  6562  loss =  0.0019949893467128277\n",
      "epoch =  27  step =  20  of total steps  6562  loss =  0.00017517821106594056\n",
      "epoch :  27  /  30  | TL :  0.0005183820678558689  | VL :  0.0005127433687448502\n",
      "saving model\n",
      "epoch =  28  step =  0  of total steps  6562  loss =  0.00026294917915947735\n",
      "epoch =  28  step =  20  of total steps  6562  loss =  0.0015313175972551107\n",
      "epoch :  28  /  30  | TL :  0.0003918464620558855  | VL :  0.00038589115138165653\n",
      "saving model\n",
      "epoch =  29  step =  0  of total steps  6562  loss =  7.166895375121385e-05\n",
      "epoch =  29  step =  20  of total steps  6562  loss =  0.0011829413706436753\n",
      "epoch :  29  /  30  | TL :  0.0003527523353806741  | VL :  0.000354610790964216\n",
      "saving model\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // train_batch_size\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '3conv2fc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20b91b34400>,\n",
       " <matplotlib.lines.Line2D at 0x20b91b34630>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(30)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
