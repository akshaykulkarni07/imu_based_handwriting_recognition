{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from torch.autograd import Variable\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171600, 15)\n",
      "(21200, 15)\n",
      "(21200, 15)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 400\n",
    "channels = 6\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('final_data/train.csv', header = None)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('final_data/test.csv', header = None)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('final_data/val.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 6 : ].values\n",
    "        ind = np.argmax(np.sum(y, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 6 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + reqd_len, : channels].values\n",
    "        x = x.astype('float')\n",
    "        x = x.reshape(reqd_len, channels)\n",
    "        assert(x.shape == (reqd_len, channels))\n",
    "        assert(label.shape == (9, ))\n",
    "        return x, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 400, 6])\n",
      "torch.Size([8, 9])\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 8\n",
    "batch_size = 2\n",
    "train_indices = [(i * reqd_len) for i in range(len(trainset) // reqd_len)]\n",
    "val_indices = [(i * reqd_len) for i in range(len(valset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(testset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)\n",
    "\n",
    "signal, label = next(iter(trainloader))\n",
    "print(signal.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398.0\n",
      "396.0\n",
      "394.0\n"
     ]
    }
   ],
   "source": [
    "# print(len(trainloader))\n",
    "# print(len(testloader))\n",
    "# print(len(valloader))\n",
    "def output_size(n, f, p = 0, s = 1):\n",
    "    return (((n + 2 * p - f) / s) + 1)\n",
    "print(output_size(400, 3))\n",
    "print(output_size(398, 3))\n",
    "print(output_size(396, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(6, 10, 3)\n",
    "        self.conv2 = nn.Conv1d(10, 15, 3)\n",
    "        self.conv3 = nn.Conv1d(15, 20, 3)\n",
    "        self.fc1 = nn.Linear(394 * 20, 512)\n",
    "        self.fc2 = nn.Linear(512, 9)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal = signal.view(-1, 6, 400)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = out.view(-1, 394 * 20)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  21450  loss =  2.3029592037200928\n",
      "epoch =  0  step =  20  of total steps  21450  loss =  3.008242130279541\n",
      "epoch =  0  step =  40  of total steps  21450  loss =  1.6029582023620605\n",
      "epoch :  0  /  30  | TL :  3.006081500143375  | VL :  1.5250192880630493\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  21450  loss =  1.472991704940796\n",
      "epoch =  1  step =  20  of total steps  21450  loss =  1.0944197177886963\n",
      "epoch =  1  step =  40  of total steps  21450  loss =  0.46291738748550415\n",
      "epoch :  1  /  30  | TL :  0.9185394667229563  | VL :  0.4250469505786896\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  21450  loss =  0.3366648554801941\n",
      "epoch =  2  step =  20  of total steps  21450  loss =  1.0221871137619019\n",
      "epoch =  2  step =  40  of total steps  21450  loss =  0.14349757134914398\n",
      "epoch :  2  /  30  | TL :  0.3175576704571832  | VL :  0.19555868208408356\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  21450  loss =  0.07231862097978592\n",
      "epoch =  3  step =  20  of total steps  21450  loss =  0.2732880413532257\n",
      "epoch =  3  step =  40  of total steps  21450  loss =  0.14296603202819824\n",
      "epoch :  3  /  30  | TL :  0.1922709909179863  | VL :  0.14177988469600677\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  21450  loss =  0.02281065657734871\n",
      "epoch =  4  step =  20  of total steps  21450  loss =  0.0185227207839489\n",
      "epoch =  4  step =  40  of total steps  21450  loss =  0.0872119888663292\n",
      "epoch :  4  /  30  | TL :  0.13492296875085472  | VL :  0.21254342794418335\n",
      "epoch =  5  step =  0  of total steps  21450  loss =  0.6460542678833008\n",
      "epoch =  5  step =  20  of total steps  21450  loss =  0.3576323390007019\n",
      "epoch =  5  step =  40  of total steps  21450  loss =  0.17521241307258606\n",
      "epoch :  5  /  30  | TL :  0.12515356085913362  | VL :  0.23209594190120697\n",
      "epoch =  6  step =  0  of total steps  21450  loss =  0.15031155943870544\n",
      "epoch =  6  step =  20  of total steps  21450  loss =  0.004621309228241444\n",
      "epoch =  6  step =  40  of total steps  21450  loss =  0.0158565454185009\n",
      "epoch :  6  /  30  | TL :  0.11346129531849106  | VL :  0.13986504077911377\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  21450  loss =  0.02544645220041275\n",
      "epoch =  7  step =  20  of total steps  21450  loss =  0.3940487802028656\n",
      "epoch =  7  step =  40  of total steps  21450  loss =  0.11715548485517502\n",
      "epoch :  7  /  30  | TL :  0.12331107784642505  | VL :  0.10956693440675735\n",
      "saving model\n",
      "epoch =  8  step =  0  of total steps  21450  loss =  0.012961405329406261\n",
      "epoch =  8  step =  20  of total steps  21450  loss =  0.03838668391108513\n",
      "epoch =  8  step =  40  of total steps  21450  loss =  0.08517962694168091\n",
      "epoch :  8  /  30  | TL :  0.07997354398534265  | VL :  0.0810510665178299\n",
      "saving model\n",
      "epoch =  9  step =  0  of total steps  21450  loss =  0.562362015247345\n",
      "epoch =  9  step =  20  of total steps  21450  loss =  0.019689228385686874\n",
      "epoch =  9  step =  40  of total steps  21450  loss =  0.03099709376692772\n",
      "epoch :  9  /  30  | TL :  0.08113090501096591  | VL :  0.107054702937603\n",
      "epoch =  10  step =  0  of total steps  21450  loss =  0.09472888708114624\n",
      "epoch =  10  step =  20  of total steps  21450  loss =  0.9819892644882202\n",
      "epoch =  10  step =  40  of total steps  21450  loss =  0.005884702317416668\n",
      "epoch :  10  /  30  | TL :  0.07281400505365487  | VL :  0.09473327547311783\n",
      "epoch =  11  step =  0  of total steps  21450  loss =  0.01715519092977047\n",
      "epoch =  11  step =  20  of total steps  21450  loss =  0.01326005905866623\n",
      "epoch =  11  step =  40  of total steps  21450  loss =  0.028290754184126854\n",
      "epoch :  11  /  30  | TL :  0.04263574744680158  | VL :  0.11671339720487595\n",
      "epoch =  12  step =  0  of total steps  21450  loss =  0.013775322586297989\n",
      "epoch =  12  step =  20  of total steps  21450  loss =  0.0030744546093046665\n",
      "epoch =  12  step =  40  of total steps  21450  loss =  0.003716203151270747\n",
      "epoch :  12  /  30  | TL :  0.038762654846683495  | VL :  0.2430569976568222\n",
      "epoch =  13  step =  0  of total steps  21450  loss =  0.06425540894269943\n",
      "epoch =  13  step =  20  of total steps  21450  loss =  0.027765098959207535\n",
      "epoch =  13  step =  40  of total steps  21450  loss =  0.10168380290269852\n",
      "epoch :  13  /  30  | TL :  0.07757524290245096  | VL :  0.2328595370054245\n",
      "epoch =  14  step =  0  of total steps  21450  loss =  0.009213943034410477\n",
      "epoch =  14  step =  20  of total steps  21450  loss =  0.008010766468942165\n",
      "epoch =  14  step =  40  of total steps  21450  loss =  0.002554339123889804\n",
      "epoch :  14  /  30  | TL :  0.03381455501207625  | VL :  0.07557042688131332\n",
      "saving model\n",
      "epoch =  15  step =  0  of total steps  21450  loss =  0.001753354794345796\n",
      "epoch =  15  step =  20  of total steps  21450  loss =  0.005400632508099079\n",
      "epoch =  15  step =  40  of total steps  21450  loss =  0.017849598079919815\n",
      "epoch :  15  /  30  | TL :  0.04936250583664075  | VL :  0.06107722967863083\n",
      "saving model\n",
      "epoch =  16  step =  0  of total steps  21450  loss =  0.005365973338484764\n",
      "epoch =  16  step =  20  of total steps  21450  loss =  0.00767643004655838\n",
      "epoch =  16  step =  40  of total steps  21450  loss =  0.04913967475295067\n",
      "epoch :  16  /  30  | TL :  0.0367235829251959  | VL :  0.1707640439271927\n",
      "epoch =  17  step =  0  of total steps  21450  loss =  0.01454134751111269\n",
      "epoch =  17  step =  20  of total steps  21450  loss =  0.029900094494223595\n",
      "epoch =  17  step =  40  of total steps  21450  loss =  0.023242520168423653\n",
      "epoch :  17  /  30  | TL :  0.04752198252321731  | VL :  0.06050584092736244\n",
      "saving model\n",
      "epoch =  18  step =  0  of total steps  21450  loss =  0.010380707681179047\n",
      "epoch =  18  step =  20  of total steps  21450  loss =  0.019815463572740555\n",
      "epoch =  18  step =  40  of total steps  21450  loss =  0.000451720436103642\n",
      "epoch :  18  /  30  | TL :  0.021804613554366987  | VL :  0.09521903097629547\n",
      "epoch =  19  step =  0  of total steps  21450  loss =  0.001993304118514061\n",
      "epoch =  19  step =  20  of total steps  21450  loss =  0.0067993770353496075\n",
      "epoch =  19  step =  40  of total steps  21450  loss =  0.033611610531806946\n",
      "epoch :  19  /  30  | TL :  0.04088410693423972  | VL :  0.26409295201301575\n",
      "epoch =  20  step =  0  of total steps  21450  loss =  0.029499739408493042\n",
      "epoch =  20  step =  20  of total steps  21450  loss =  0.0022310204803943634\n",
      "epoch =  20  step =  40  of total steps  21450  loss =  0.0016108308918774128\n",
      "epoch :  20  /  30  | TL :  0.033045327949847256  | VL :  0.10004561394453049\n",
      "epoch =  21  step =  0  of total steps  21450  loss =  0.0004368547524791211\n",
      "epoch =  21  step =  20  of total steps  21450  loss =  0.30712804198265076\n",
      "epoch =  21  step =  40  of total steps  21450  loss =  0.0065725878812372684\n",
      "epoch :  21  /  30  | TL :  0.027934935040286532  | VL :  0.09229155629873276\n",
      "epoch =  22  step =  0  of total steps  21450  loss =  0.0172224510461092\n",
      "epoch =  22  step =  20  of total steps  21450  loss =  0.00172868138179183\n",
      "epoch =  22  step =  40  of total steps  21450  loss =  0.0026572681963443756\n",
      "epoch :  22  /  30  | TL :  0.02506403120252181  | VL :  0.0685708299279213\n",
      "epoch =  23  step =  0  of total steps  21450  loss =  0.0051140631549060345\n",
      "epoch =  23  step =  20  of total steps  21450  loss =  0.0014080109540373087\n",
      "epoch =  23  step =  40  of total steps  21450  loss =  0.004202838055789471\n",
      "epoch :  23  /  30  | TL :  0.016840537138533656  | VL :  0.04685742035508156\n",
      "saving model\n",
      "epoch =  24  step =  0  of total steps  21450  loss =  0.0017250434029847383\n",
      "epoch =  24  step =  20  of total steps  21450  loss =  0.0013013177085667849\n",
      "epoch =  24  step =  40  of total steps  21450  loss =  0.0018522044410929084\n",
      "epoch :  24  /  30  | TL :  0.03844787377492362  | VL :  0.17767445743083954\n",
      "epoch =  25  step =  0  of total steps  21450  loss =  0.0015756108332425356\n",
      "epoch =  25  step =  20  of total steps  21450  loss =  0.0011737440945580602\n",
      "epoch =  25  step =  40  of total steps  21450  loss =  0.010972052812576294\n",
      "epoch :  25  /  30  | TL :  0.03718283047179147  | VL :  0.0707198828458786\n",
      "epoch =  26  step =  0  of total steps  21450  loss =  0.005145193077623844\n",
      "epoch =  26  step =  20  of total steps  21450  loss =  0.0052719986997544765\n",
      "epoch =  26  step =  40  of total steps  21450  loss =  0.00731429411098361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  26  /  30  | TL :  0.059972180755927564  | VL :  0.084590382874012\n",
      "epoch =  27  step =  0  of total steps  21450  loss =  0.008648348040878773\n",
      "epoch =  27  step =  20  of total steps  21450  loss =  0.001362097798846662\n",
      "epoch =  27  step =  40  of total steps  21450  loss =  0.0009781268890947104\n",
      "epoch :  27  /  30  | TL :  0.017189878304840398  | VL :  0.04839883744716644\n",
      "epoch =  28  step =  0  of total steps  21450  loss =  0.0011327445972710848\n",
      "epoch =  28  step =  20  of total steps  21450  loss =  0.001324089476838708\n",
      "epoch =  28  step =  40  of total steps  21450  loss =  0.0009485339978709817\n",
      "epoch :  28  /  30  | TL :  0.016406225004312495  | VL :  0.04894803464412689\n",
      "epoch =  29  step =  0  of total steps  21450  loss =  0.021415645256638527\n",
      "epoch =  29  step =  20  of total steps  21450  loss =  0.0005858917720615864\n",
      "epoch =  29  step =  40  of total steps  21450  loss =  0.45238062739372253\n",
      "epoch :  29  /  30  | TL :  0.016792639956687675  | VL :  0.07136289775371552\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // train_batch_size\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '3conv2fc_x_acc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x231ea7d07f0>,\n",
       " <matplotlib.lines.Line2D at 0x231ea7d06a0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(30)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = ConvNet().eval()\n",
    "Net.load_state_dict(torch.load('3conv2fc_x_acc.pt'))\n",
    "# print(Net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv1d(6, 10, kernel_size=(3,), stride=(1,))\n",
       "  (conv2): Conv1d(10, 15, kernel_size=(3,), stride=(1,))\n",
       "  (conv3): Conv1d(15, 20, kernel_size=(3,), stride=(1,))\n",
       "  (fc1): Linear(in_features=7880, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_accuracy(dataloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "#         print(images)\n",
    "        outputs = Net(images)\n",
    "#         print('Output : ')\n",
    "#         print(outputs)\n",
    "        \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "#         print('Label : ')\n",
    "#         print(label_ind)\n",
    "#         print('Prediction : ')\n",
    "#         print(pred_ind)\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "#         print('correct - ', correct, ' of ', total, 'as of now')\n",
    "#         print('image - ', total, ' of ', len(dataloader.dataset) // 80)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net.cpu()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9976415094339622\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader))\n",
    "print(_get_accuracy(valloader))\n",
    "print(_get_accuracy(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
